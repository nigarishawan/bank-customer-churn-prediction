# -*- coding: utf-8 -*-
"""Bank customer churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1meJPSi98fSfoNg2vBHWoB4NPUrF_KX-9
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset (You will need to upload the dataset to Colab)
from google.colab import files
uploaded = files.upload()

# Load dataset dynamically by accessing the first key in the uploaded dictionary
import io
file_name = next(iter(uploaded))  # Get the uploaded file name dynamically
data = pd.read_csv(io.BytesIO(uploaded[file_name]))

# Encode categorical variables
label_encoder = LabelEncoder()

# Encode the 'country' and 'gender' columns
data['country'] = label_encoder.fit_transform(data['country'])
data['gender'] = label_encoder.fit_transform(data['gender'])

# Split the data into features and target
X = data.drop(columns=['customer_id', 'churn'])
y = data['churn']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize classifiers
classifiers = {
    "RandomForest": RandomForestClassifier(),
    "AdaBoost": AdaBoostClassifier(),
    "GradientBoosting": GradientBoostingClassifier(),
    "Bagging": BaggingClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(probability=True),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
}

# Dictionary to store the performance metrics
metrics = {}

# Function to plot the confusion matrix
def plot_confusion_matrix(cm, name):
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {name}")
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.show()

# Train and evaluate each classifier
plt.figure(figsize=(10, 8))

for name, clf in classifiers.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    y_proba = clf.predict_proba(X_test)[:, 1]  # For ROC curve

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plot_confusion_matrix(cm, name)

    # ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')

    # Store metrics for comparison
    metrics[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }

# Finalize ROC curve plot
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend(loc="lower right")
plt.show()

# Convert metrics dictionary to a DataFrame for better readability
metrics_df = pd.DataFrame(metrics).T

# Display the performance comparison of classifiers
print(metrics_df)

# Plotting the bar graph for comparison of performance metrics
metrics_df.plot(kind='bar', figsize=(12, 8))
plt.title('Classifier Performance Comparison')
plt.ylabel('Scores')
plt.xticks(rotation=45)
plt.legend(loc="lower right")
plt.show()